---
title: "How to save a life? Titanic edition"
output: github_document
---

```{r setup, include=FALSE}
## Author:              Josh Valdeleon
## Published:           August 18, 2021

knitr::opts_chunk$set(echo = FALSE, fig.width = 15, fig.height = 8, warning = F)

## Read packages
library(readr)
library(dplyr)
library(ggplot2)
library(ggtext)
library(caret)

## Read the training data
train <- read_csv('train.csv')

## Remove unnecessary columns
d_cols <- c('Name', 'Ticket', 'Cabin')
train[, d_cols] <- list(NULL)

## Set default ggplot theme and settings
theme_set(theme_minimal())
theme_replace(plot.title = element_markdown(size = 20, face= "bold", hjust=0),
              plot.subtitle = element_markdown(size = 16, hjust=0),
              legend.position = 'none',
              plot.margin = margin(4,2,2,4, unit = 'mm'))
```

Around April 1912, you onboarded the famous **RMS Titanic cruise liner**. Along with other 2,200+ passengers, you enjoyed the few days you'd spent in that massive and elegant ship until one night, it started sinking to the bottom of the North Atlantic Ocean. You're so scared as you don't know if you'd survive or get drowned or freeze to death. You fell off from the gigantic ship into the ocean---and that wakes you up. "***Phew!***" It was all just a dream, and you're living in 2021's climate crisis and pandemic.

<br>

You heard on the news that scientists and engineers are testing the time machine they're developing. With high hopes, traveling back in time would be possible by 2060s. As a healthy 24 year old guy, you have some confidence that you'll still be alive by then and that you'll get to travel back in time. As an aspiring data scientist, you thought of analyzing the Titanic passengers' data to assess which features would help people to survive from the sinking ship. *Of course, you thought of telling everyone that Titanic will sink on 1912 April 15th, but who will believe a "prophetic" weird looking man telling them what will happen in the future? So you thought of a little bit more logical way to help them ---***give them the statistics on passengers' survival from a sinking boat**.

<br>

> "Data is the new oil. Does that mean that it will also give the same problems that oil had caused?" --- *Unknown (actually, mine but maybe someone had already said it)*

<br>

### About the data

```{r}
train
```

Thanks to the internet, you managed to get several details about the **1,309** **Titanic passengers**. For the event that happened centuries ago, it's cool that you still have enough passenger-level information that's fairly clean. Of course, there are missing values and variables. You have **418 samples** with missing survival status. With the help of [Kaggle](https://www.kaggle.com/c/titanic), you'll get to test your data analysis skills to measure people's chances of surviving from that catastrophic event through prediction (*which we can call scientific fortune-telling*).

<br>

### Exploratory Data Analysis

Couple of days after that dream of being one of the fortunate/unfortunate passengers of RMS Titanic, you finally got some initial results from your analysis!

<br>

#### On passenger class.

```{r}
## Group by survived and passenger class
suv_by_class <- train %>%
        group_by(Pclass) %>%
        summarise(r=sum(Survived)/n())

## Create bar graph of survival rate per class
suv_by_class %>%
        ggplot(aes(x=Pclass, y=r)) + 
        geom_bar(stat='identity', fill=c('#00B0F0', 'grey30', 'grey30')) +
        coord_flip() +
        scale_x_continuous(minor_breaks = NULL) +
        scale_y_continuous(minor_breaks = NULL, limits = c(0, 1), breaks=seq(0, 1, 0.5)) +
        labs(x='Passenger Class', y='Survival%', 
             title='Survival rate is <span style="color:#00B0F0">higher for high class passengers (63%)</span>',
             subtitle='<b>While only 47% and 24% survived</b> from classes 2 and 3 respectively') +
        geom_text(aes(label=paste0(round(r, 2) * 100, '%')), hjust=-1)
```

Your hunch is a *little* true. **People from higher classes had higher survival%**. Survival% can be thought of as the probability of surviving from the sinking Titanic ship given a specific class. We denote this by $P(S|C_n)$, which is read as "*the probability of surviving given class n*". So, $P(S|C_1)$=63%, $P(S|C_2)$=47%, while $P(S|C_3)$=24%.

<br>

#### On fares class.

```{r}
## Create boxplot of fare grouped by `Survived`
train %>%
        mutate(Survived = ifelse(Survived == 1, 'Survived', 'Didn\'t survive')) %>%
        ggplot(aes(x=Fare)) + 
        geom_boxplot(aes(fill=Survived), color='grey70') +
        theme(legend.position='bottom', legend.title = NULL) + 
        scale_fill_manual(values=c('#FF6363', '#00B0F0')) + 
        scale_x_continuous(minor_breaks=NULL) +
        scale_y_continuous(breaks=NULL, minor_breaks=NULL) +
        labs(title='Those people who paid <span style="color:#00B0F0">higher fares</span> had more chances of surviving',
             subtitle='While majority of those who didn\'t survive <span style="color:#FF6363"><b>had paid lower fares</b></span>')
```

Visualizing the fares of the passengers gave you more evidence that *with great power comes with great survival rate*. You can see from these boxplots that **those who paid higher fare had more survivors than those who paid less**. You may wonder, *what did someone get for paying more than \$500*? Well, that's the [price for a first class ticket](https://www.statisticalconsultants.co.nz/blog/titanic-fare-data.html).

<br>

> "Data is the new pollution. When data is not clean, it becomes a liability."\
>  *--- Dr. Dominic Ligot*

<br>

#### On age.

```{r}
## Create boxplot of age grouped by `Survived`
train %>%
        mutate(Survived = ifelse(Survived == 1, 'Survived', 'Didn\'t survive')) %>%
        ggplot(aes(x=Age)) + 
        geom_boxplot(aes(fill=Survived), color='grey70') +
        theme(legend.position='bottom', legend.title = NULL) + 
        scale_fill_manual(values=c('#FF6363', '#00B0F0')) + 
        scale_x_continuous(minor_breaks=NULL) +
        scale_y_continuous(breaks=NULL, minor_breaks=NULL) +
        labs(title='The boxplots seem to show similar distribution with slight overlaps',
             subtitle='<span style="color:#00B0F0"><b>Majority of the survivors are younger</b></span> than those who didn\'t survive by a couple of years')
```

Age doesn't seem to be a great predictor of passenger's survival. Distribution of age grouped by survival status looks similar, although by running a T-Test, you found out that on average, **those who survived are younger by 2 years** than those who didn't make it (1--5 years on 95% confidence).

<br>

#### On sex.

```{r}
## Group by survived and passenger class
suv_by_sex <- train %>%
        group_by(Sex) %>%
        summarise(r=sum(Survived)/n())
        
## Create bar graph of survival rate per sex
suv_by_sex %>%
        ggplot(aes(x=Sex, y=r)) +
        geom_bar(stat='identity', fill=c('#FF6363','#00B0F0')) +
        coord_flip() +
        scale_y_continuous(minor_breaks = NULL, limits = c(0, 1), breaks=seq(0, 1, 0.5)) +
        labs(x='Sex', y='Survival%', 
             title='Survival rate is <span style="color:#FF6363">higher on females</span> than males',
             subtitle='Per the movie, <b>women and children got on to rubber boats first</b> before males') +
        geom_text(aes(label=paste0(round(r, 2) * 100, '%')), hjust=-1)
```

Females had the highest survival rate. **74% of the female passengers** **survived** from the sinking ship while only **19% of the male passengers made it**. You kinda watched the movie and you saw that females and children went to the rubber boats first before males. This is also called [**Birkenhead Drill**](https://en.wikipedia.org/wiki/Women_and_children_first). There's also an interesting story of misunderstanding the captain's order where one officer interpreted it as "*women and children **first**"* while the other officer thought of it as "*women and children **only***", which could explain your recent findings from the age and sex data.

<br>

#### **On number of siblings/spouse and parents/children aboard, and port of embarkation.**

```{r}
## Group by survived and number of siblings/spouse
suv_by_sibsp <- train %>%
        group_by(SibSp) %>%
        summarise(r=sum(Survived)/n())

## Group by survived and number of parent/children
suv_by_parch <- train %>%
        group_by(Parch) %>%
        summarise(r=sum(Survived)/n())

## Group by survived and embarked
## NAs were replaced by mode ('S')
train %>% 
        mutate(Embarked = ifelse(is.na(Embarked), 'S', Embarked)) %>%
        group_by(Embarked) %>%
        summarise(r=sum(Survived)/n()) -> suv_by_emb

## SibSp survival rate
f1 <- suv_by_sibsp %>%
        ggplot(aes(x=SibSp, y=r)) + 
        geom_bar(stat='identity') +
        scale_x_continuous(minor_breaks = NULL, breaks=seq(0, 8, 1)) +
        scale_y_continuous(minor_breaks = NULL, limits = c(0, 1), breaks=seq(0, 1, 0.5)) +
        labs(x='Siblings/Spouse count', y='Survival%') + 
        geom_text(aes(label=paste0(round(r, 2) * 100, '%')), vjust=-1)

## Parch survival rate
f2 <- suv_by_parch %>%
        ggplot(aes(x=Parch, y=r)) + 
        geom_bar(stat='identity') +
        scale_x_continuous(minor_breaks = NULL, breaks=seq(0, 6, 1)) +
        scale_y_continuous(minor_breaks = NULL, limits = c(0, 1), breaks=seq(0, 1, 0.5)) +
        labs(x='Parent/Children count', y='Survival%') + 
        geom_text(aes(label=paste0(round(r, 2) * 100, '%')), vjust=-1)

## Embarked survival rate
f3 <- suv_by_emb %>%
        ggplot(aes(x=Embarked, y=r)) + 
        geom_bar(stat='identity') +
        scale_y_continuous(minor_breaks = NULL, limits = c(0, 1), breaks=seq(0, 1, 0.5)) +
        labs(x='Embarked', y='Survival%') + 
        geom_text(aes(label=paste0(round(r, 2) * 100, '%')), vjust=-1)

## Visualize f1 and f2
ggpubr::ggarrange(f1, f2, f3, 
                  labels = c('SibSp Survival%', 'Parch Survival%', 'Embarked Survival%'),
                  nrow=3)
```

To summarize the final pieces of the data, **survival% generally decreases as people bring more siblings/spouse aboard**, although it's a little weird why those with no siblings nor spouses had lower survival%. Bringing your parents/children with you doesn't visually say your chances of surviving. You see that there's no clear direction, and that **survival is still a matter of chances for this aspect**. As for port of embarkation, **passengers embarked from Cherbourg had the highest survival%**, followed by Queenstown, and Southampton respectively Although there are some clear distinctions, you are still doubtful on whether port of embarkation is a good measure of survival (*just think of it, will people ask you at which port you onboarded during a life and death situation?*).

<br>

### Data Cleaning & Feature Selection

The above results were derived from the raw data. So, you went on working with missing values and make some transformations.

<br>

#### **Imputing missing values.**

```{r}
## Handling missing age values
random_range_encoder <- function(rang) {
        
        ## This function encodes missing values
        ## with a random number based from the 
        ## minimum and maximum value of the 
        ## data.
        
        x_min <- min(rang, na.rm = T)
        x_max <- max(rang, na.rm = T)
        
        sapply(rang, imputer <- function(x) {
                if (is.na(x)) {
                        return(runif(1, x_min, x_max))
                } else {
                        return(x)
                }
        })
        
}

## Visualize the distribution of age 
## before imputation
q1 <- train %>% 
        ggplot(aes(x=Age)) + 
        geom_density(size=1, fill='steelblue')

## Setting seed for reproducibility
set.seed(123)

## Impute missing age values
train$Age <- random_range_encoder(train$Age)

## Visualize the distribution of age 
## after imputation
q2 <- train %>% 
        ggplot(aes(x=Age)) + 
        geom_density(size=1, fill='steelblue')

## Display both plots
ggpubr::ggarrange(q1, q2, labels=c('Before random imputation', 'After random imputation'))

## There maybe some changes but the distribution
## Still looked similar
```

You actually tried imputing values with mean and median age but that drastically changed the distribution of this variable. You thought of using complex methods, but you want to make it simple. So, you replaced NAs with **random uniform values ranges from the actual minimum and maximum values** of this variable, which you think is more sensible as this reflects the real data that you have (with the assumption that data are just *missing at random*). There are also **2 missing values** on port of embarkation. You imputed them with the **mode** which is Southampton. 

<br>

#### **Data transformation.**

```{r}
## Recode sex to binary
train$Sex <- ifelse(tolower(train$Sex) == 'female', 1, 0)

## Dummy variables for Embarked (reference='Q')
## Replace NA with mode='S'
train$Embarked <- ifelse(is.na(train$Embarked), 'S', train$Embarked)
train$emb_s <- ifelse(train$Embarked == 'S', 1, 0)
train$emb_c <- ifelse(train$Embarked == 'C', 1, 0)
train[, 'Embarked'] <- list(NULL)

## Change to factor
train$Survived <- factor(train$Survived)

## Remove PassengerId
train[, 1] <- list(NULL)

## Save a copy of complete cleaned data
train_set_0 <- train

## Data with personally selected features
d_cols <- c('Pclass', 'Parch', 'emb_s', 'emb_c')
train[, d_cols] <- list(NULL)
```

You transformed sex variable to make it a numeric data. In your transformation, 1 means *female* while 0 means *male*. You've also made some dummy variables for port of embarkation. Finally, you converted your outcome variable to **factor**.

<br>

#### **Feature selection.**

You had selected the features that you will use for your model. After several brainstorming (*just with yourself*), you've removed passenger id (*obviously, since this is just an identifier*), number of parent/child aboard (*since per your EDA, survival% is not easy to be identified using this*), port of embarkation (*you're not that sold with the idea that this can be a good predictor*), and passenger class (*you will use fare instead, and fare will still tell which class you're on*). But you kept a copy of the cleaned and transformed dataset for comparison purposes.

<br>

#### **Variable importance.**

```{r}
## Get feature importance
set.seed(123)
tr <- trainControl(method='repeatedcv', number=10, repeats=10)
rf_0 <- train(Survived~., data=train_set_0, method='rpart', trControl=tr)
rf_1 <- train(Survived~., data=train, method='rpart', trControl=tr)

vi_0 <- data.frame(
        vars=row.names(varImp(rf_0, scale=FALSE)$importance), 
        varImp(rf_0, scale=FALSE)$importance, 
        row.names = NULL)

vi_1 <- data.frame(
        vars=row.names(varImp(rf_1, scale=FALSE)$importance), 
        varImp(rf_1, scale=FALSE)$importance, 
        row.names = NULL)

v0 <- vi_0 %>% 
        ggplot(aes(x=reorder(vars, Overall), y=Overall)) +
        geom_bar(stat='identity') + 
        coord_flip() + 
        labs(x='variables')

v1 <- vi_1 %>%
        ggplot(aes(x=reorder(vars, Overall), y=Overall)) + 
        geom_bar(stat='identity') +
        coord_flip() +
        labs(x='variables')

ggpubr::ggarrange(v0, v1, nrow=2, labels=c('All features', 'Personally selected features'))
```

You trained two random forest models to get the variable importance. The first model has all features while the second one has the features you've hand-picked. Both models agree that **passenger's sex is the most important variable**, followed by **passenger class** (present only in the first model), and **fare paid**. You want to account for the findings you got from this test. Hence, in the model you will use for prediction, you will just use the **passenger's sex**, **fare paid**, and **their class**.

<br>

> "*I love hasty generalization. This is just really telling you that you can't measure a phenomena with 100% certainty.*" --- Just me, making it look like a good quote

<br>

### Building the model

Okay, so you're now on the final steps to save some people from the elegant yet horrifying disaster. You will now build some classifiers to see which one performs best.

<br>

#### Logistic regression.

```{r}
## Segregate the survivors from those who 
## didn't make it 
suv_0 <- filter(train, Survived == 0)
suv_1 <- filter(train, Survived == 1)

## Perform undersampling since we have
## less survivors
set.seed(123)
suv_0_part <- sample(1:dim(suv_0)[1], dim(suv_1)[1])
suv_0_sam <- suv_0[suv_0_part, ]
suv_0_rem <- suv_0[-suv_0_part, ] ## we'll use this later

## Merge the two dataframes
equal_data <- rbind(suv_1, suv_0_sam)

## Create data partition
set.seed(123)
train_index <- createDataPartition(equal_data$Survived, p=0.8, list=FALSE)
train_data <- equal_data[train_index, ]
val_data <- equal_data[-train_index, ]

## Define train control
tr <- trainControl(method='repeatedcv', number=10, repeats=10)

## Build logistic regression
logit <- train(Survived~., data=train_data, method='glm', family='binomial')

## Accuracy on training data
confusionMatrix(data=predict(logit), reference=train_data$Survived)

## Accuracy on validation
confusionMatrix(data=predict(logit, newdata=val_data[, -1]), reference=val_data$Survived)
```

You ran a logistic regression and your model didn't show any signs of overfitting but the accuracy is below 80%. On training data (first result), you got **75.55%** accuracy while on validation data (second result), you got **81.62%**.

<br>

#### Decision tree.

```{r}
## Build decision tree (for classification, outcome must be a factor)
set.seed(123)
tree <- train(Survived~., data=train_data, method='treebag', trControl=tr)

## Accuracy on training data (for classification, outcome must be a factor)
confusionMatrix(data=predict(tree), reference=train_data$Survived)

## Accuracy on validation data (for classification, outcome must be a factor)
confusionMatrix(data=predict(tree, newdata=val_data[, -1]), reference=val_data$Survived)
```

Next, you've trained a decision tree model. It's great that this acquired **99.09%** accuracy rate on training data (first result), but the validation set (second result) shows a clear sign of overfitting as you only had **77.94%** accuracy. 

<br>

#### Random forest.

```{r}
## Build random forest (for classification, outcome must be a factor)
set.seed(123)
rf <- train(Survived~., data=train_data, method='rpart', trControl=tr)

## Accuracy on training data (for classification, outcome must be a factor)
confusionMatrix(data=predict(rf), reference=train_data$Survived)

## Accuracy on validation data (for classification, outcome must be a factor)
confusionMatrix(data=predict(rf, newdata=val_data[, -1]), reference=val_data$Survived)
```

This is the last model that you fitted. On training set (left), you got **79.20%** accuracy which is lower than the second model's predictions, but higher than the first one. On the validation set. you had **79.41%** accuracy, which is an improvement but is still low.

<br>

> "*Never defend your model.*" --- I'm just making some random statements. Maybe my name will be posted elsewhere for these quotes.

<br>

### Testing the model

So, after you've trained couple of models, you have generated some predictions based from that 418 samples with no labeled output. This is where Kaggle will help you. *Magically*, Kaggle will assess your predictions and will give you the accuracy rate of your submission. You have prepared four predictions: the first three are based from the models that you've fit, and the last one was based on the ***ensemble*** of those models. The fourth predictions were made by *voting*. If **two or more models** voted for a specific class, then the **prediction will be in favor for that class**.

![](submissions.png)

Using the 418 unlabeled test data, logistic regression gave you **70.57% accuracy**, decision tree yielded **73.68%**, while for random forest, it's **71.53%**. Their combined predictions gave you **75.83%**. "*Geez! So, if I'll use my model to advise the 2,200+ Titanic passengers, I will only be correct for roughly 1,650 of them. From the overall probability (\~31%) of surviving that incident, my model may only save 512 passengers.*"

<br>

> "*If you can travel back in time, will you back to historic events to change it? But can you really change it?*"

<br>

### Farewell

Although the accuracy that you have from the unseen data is not *generally* good, your analyses still yielded meaningful results. By the time that you will travel back to 1912, you'll bring these statistics to inform the passengers about their chances of surviving should the Titanic ship sinks (*but you know that it will*). Maybe they'll ignore and look down on you (*because your outfit would seem really odd for them*), but at least, you gave them a warning (*you haven't actually thought if everyone knows modern English*). 

2060s is still far. So, you have plenty of time to make better models that predict with better accuracy. Time travel may still be impossible by then, so you could take your time as you develop better ways on how to save more people (*if not, prevent that tragedy*).

Oh, you thought of a simpler way to avoid that incident. Look for Jack and Rose and tell them not to kiss in that spot where they were seen by the ship guard. He got distracted and didn't see that incoming iceberg. 
